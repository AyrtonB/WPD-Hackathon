# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01-data-processing.ipynb (unless otherwise specified).

__all__ = ['clean_real_power_df', 'load_real_power_dataset', 'load_datetime_df', 'load_weather_df',
           'construct_baseline_features_target_dfs']

# Cell
import numpy as np
import pandas as pd

import os

# Cell
def clean_real_power_df(
    df: pd.DataFrame,
    cols_to_keep: list=['maxvalue', 'minvalue', 'value_max', 'value_min', 'quality', 'samplecount', 'value']
):
    if 'attrId' in df.columns:
        assert df['attrId'].reset_index().duplicated().sum() == 0, 'The time and attrId data must contain no duplicate rows'
        assert df['attrId'].value_counts().size == 1, 'Only one `attrId` value should be contained in the dataset'

    if 'units' in df.columns:
        assert df['units'].value_counts().size == 1, 'Only one `units` value should be contained in the dataset'

    df_clean = df[sorted(list(set(cols_to_keep).intersection(set(df.columns))))].copy()

    return df_clean

def load_real_power_dataset(
    data_dir: str,
    site: str='Geevor_CB52',
    real_power_variable: str='minute',
    time_period: str=''
):
    valid_time_periods = ['', '_august', '_pre_august', '_september', '_pre_september']
    valid_real_power_variables = ['minute', 'observation_variable_half_hourly', 'target_variable_half_hourly_max_min']
    assert real_power_variable in valid_real_power_variables, f'`real_power_variable` must be one of {", ".join(valid_real_power_variables)}'
    assert time_period in valid_time_periods, f'`time_period` must be one of {", ".join(valid_time_periods)}'

    if time_period == '_pre_september':
        df_pre_august = load_real_power_dataset(data_dir, site, real_power_variable, '_pre_august')
        df_august = load_real_power_dataset(data_dir, site, real_power_variable, '_august')
        df_pre_september = df_pre_august.append(df_august)
        return df_pre_september

    fp = f'{data_dir}/MW_{site}_MW_{real_power_variable}_real_power_MW{time_period}.csv'

    df = pd.read_csv(fp)

    if 'Unnamed: 0' in df.columns:
        df = df.drop(columns=['Unnamed: 0'])

    df['time'] = pd.to_datetime(df['time'], utc=True)
    df = df.set_index('time')

    df = clean_real_power_df(df)

    return df

# Cell
def load_datetime_df(fp, col_suffix=None):
    df = pd.read_csv(fp)

    df['datetime'] = pd.to_datetime(df['datetime'], utc=True)
    df = df.set_index('datetime')

    if col_suffix is not None:
        df.columns = [f'{col}_{col_suffix}' for col in df.columns]

    return df

def load_weather_df(
    weather_data_dir: str='data/weather',
    sites: list=['staplegrove'],
    grid_points: type(None)=None,
    interpolate_method: str='interpolate'
):
    def valid_grid_points(filename, grid_points):
        is_valid = False

        if grid_points is None:
            return True

        for grid_point in grid_points:
            if str(grid_point) in filename:
                is_valid = True

        return is_valid

    def valid_sites(filename, sites):
        if isinstance(sites, str):
            sites = [sites]

        for site in sites:
            if site in filename:
                return True

        return False

    df = pd.concat([
        load_datetime_df(f'{weather_data_dir}/{filename}', f"{filename.split('_')[1]}_{filename.replace('_hourly.csv', '').split('_')[-1]}")
        for filename
        in os.listdir(weather_data_dir)
        if ('.csv' in filename) and valid_sites(filename, sites) and valid_grid_points(filename, grid_points)
    ], axis=1)

    if interpolate_method is not None:
        dt_rng = pd.date_range(df.index.min(), df.index.max(), freq='30T')
        df = getattr(df.reindex(dt_rng), interpolate_method)()

    return df

# Cell
def construct_baseline_features_target_dfs(
    data_dir: str='data',
    real_power_sub_dir: str='real_power',
    weather_sub_dir: str='weather',
    real_power_time_period: str='_pre_august',
    real_power_site: str='Staplegrove_CB905',
    weather_sites: list=['staplegrove'],
    weather_grid_points: type(None)=None,
    weather_interpolate_method: str='interpolate',
    use_target_delta: bool=False
):
    df_observation = load_real_power_dataset(f'{data_dir}/{real_power_sub_dir}', site=real_power_site, real_power_variable='observation_variable_half_hourly', time_period=real_power_time_period)
    df_target = load_real_power_dataset(f'{data_dir}/{real_power_sub_dir}', site=real_power_site, real_power_variable='target_variable_half_hourly_max_min', time_period=real_power_time_period)
    df_weather = load_weather_df(f'{data_dir}/{weather_sub_dir}', sites=weather_sites, grid_points=weather_grid_points, interpolate_method=weather_interpolate_method)

    common_idxs = df_observation.index.intersection(df_weather.index).intersection(df_target.index)

    df_features = df_observation.loc[common_idxs].copy()
    df_features[df_weather.columns] = df_weather.loc[common_idxs].copy()
    df_target = df_target.loc[common_idxs]

    if use_target_delta == True:
        assert 'value' in df_features.columns
        df_target = df_target.subtract(df_features['value'], axis=0)

    return df_features, df_target