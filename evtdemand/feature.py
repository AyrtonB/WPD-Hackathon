# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03a-feature-generation.ipynb (unless otherwise specified).

__all__ = ['dt_rng_to_SPs', 'create_temporal_features', 'create_dir_speed_features', 'add_col_suffix', 'isfloat',
           'iterate_feature_gen_over_site_gridpoints', 'get_grid_points', 'calc_hcdh_factor', 'create_hcdh_features',
           'create_feature_stats', 'create_combined_feature_stats', 'create_demand_stat_features',
           'create_solar_features', 'create_prev_month_stats_df', 'create_lagged_df', 'creat_demand_ts_pcs',
           'create_rate_of_change_features', 'clean_and_normalise_data', 'process_features',
           'create_additional_features']

# Cell
import numpy as np
import pandas as pd

from copy import copy
from evtdemand import data
from sklearn.decomposition import PCA

# Cell
def dt_rng_to_SPs(
    start_date: pd.Timestamp,
    end_date: pd.Timestamp,
    freq: str='30T',
    tz: str='Europe/London'
):
    dt_rng = pd.date_range(start_date, end_date, freq=freq, tz=tz)

    SPs = list((2*(dt_rng.hour + dt_rng.minute/60) + 1).astype(int))
    dt_strs = list(dt_rng.strftime('%Y-%m-%d'))

    df_dates_SPs = pd.DataFrame({'date':dt_strs, 'SP':SPs}, index=dt_rng).astype(str)

    # Accounting for clock changes
    clock_change_dt_idxs_dir = pd.Series(dt_rng).apply(lambda dt: dt.utcoffset().total_seconds()).diff().replace(0, np.nan).dropna()

    for dt_idx, dir_ in clock_change_dt_idxs_dir.items():
        dt = dt_rng[dt_idx].date()
        SPs = (1 + 2*(dt_rng[dt_rng.date==dt] - pd.to_datetime(dt).tz_localize('Europe/London')).total_seconds()/(60*60)).astype(int)

        df_dates_SPs.loc[df_dates_SPs.index.date==dt, 'SP'] = SPs

    return df_dates_SPs

def create_temporal_features(df_features: pd.DataFrame):
    df_dates_SPs = dt_rng_to_SPs(
        df_features.index.min().strftime('%Y-%m-%d %H:%M'),
        df_features.index.max().strftime('%Y-%m-%d %H:%M')
    )

    df_dates_SPs.index = df_dates_SPs.index.tz_convert('UTC')

    df_temporal = pd.DataFrame({
        # 'SP': df_dates_SPs['SP'].values,
        'hour': df_features.index.hour + df_features.index.minute/60,
        'local_hour': df_features.index.tz_convert('Europe/London').hour + df_features.index.tz_convert('Europe/London').minute/60,
        'weekday': df_features.index.dayofweek,
        'weekend': df_features.index.dayofweek.isin([5, 6]),
        'doy': df_features.index.dayofyear,
        'month': df_features.index.month
    }, index=df_features.index)

    return df_temporal

# Cell
def create_dir_speed_features(df_features: pd.DataFrame, site_gridpoint: str='staplegrove_1'):
    s_U, s_V = df_features[f'windspeed_east_{site_gridpoint}'], df_features[f'windspeed_north_{site_gridpoint}']

    df_speed_dir = pd.DataFrame({
        'direction': np.mod(180 + np.rad2deg(np.arctan2(s_U, s_V)), 360),
        'speed': np.sqrt(s_U**2 + s_V**2)
    })

    return df_speed_dir

def add_col_suffix(df, col_suffix: str='', col_prefix: str=''):
    df.columns = [f'{col_prefix}_{col}_{col_suffix}'.strip('_') for col in df.columns]

    return df

def isfloat(value):
    try:
        float(value)
        return True
    except ValueError:
        return False

get_grid_points = lambda df_features, site: sorted(list(set([int(col.split(f'{site}_')[-1]) for col in list(df_features.columns[df_features.columns.str.contains(site)]) if isfloat(col.split(f'{site}_')[-1])])))

def iterate_feature_gen_over_site_gridpoints(
    df_features: pd.DataFrame,
    feature_gen_function: type(lambda x: x),
    sites: list=['staplegrove'],
    grid_points: type(None)=None,
    **kwargs
):
    """Accepts a function that can be passed `df_features` and `site_gridpoint`"""

    grid_points_original = copy(grid_points)
    combined_dfs = []

    for site in sites:
        if grid_points_original is None:
            grid_points = get_grid_points(df_features, site)

        combined_dfs += [
            feature_gen_function(df_features, f'{site}_{grid_point}', **kwargs).pipe(add_col_suffix, f'{site}_{grid_point}')
            for grid_point
            in grid_points
        ]

    df = pd.concat(combined_dfs, axis=1)

    return df

# Cell
def calc_hcdh_factor(
    t: float,
    hbt: float=10,
    cbt: float=20,
    beta_0: float=0,
    beta_1: float=1,
    beta_2: float=2
):
    if isinstance(t, pd.Series):
        hdh = (hbt-t).to_frame().assign(ref=0).max(axis=1)
        cdh = (t-cbt).to_frame().assign(ref=0).max(axis=1)

    else:
        hdh = max(0, hbt-t)
        cdh = max(0, t-cbt)

    hcdh_factor = beta_0 + beta_1*hdh + beta_2*cdh

    return hcdh_factor

def create_hcdh_features(df_features: pd.DataFrame, site_gridpoint: str='staplegrove_1'):
    df_hcdh_factor = calc_hcdh_factor(df_features[f'temperature_{site_gridpoint}']).to_frame()
    df_hcdh_factor = df_hcdh_factor.rename(columns={0: f'hcdh'})

    return df_hcdh_factor

# Cell
def create_feature_stats(
    df_features: pd.DataFrame,
    cols: list=['value'],
    method_1: str='rolling',
    method_2: str='mean',
    method_1_kwargs: dict={'window': 2},
    method_2_kwargs: dict={},
    col_names: list=[]
):
    if isinstance(cols, str):
        cols = [cols]

    if method_2 is None:
        df_feature_stats = getattr(df_features[cols], method_1)(**method_1_kwargs)
        method_2_str = ''
    else:
        df_feature_stats = getattr(getattr(df_features[cols], method_1)(**method_1_kwargs), method_2)(**method_2_kwargs)
        method_2_str = method_2 + '__' + '_'.join([f'{k}_{v}' for k, v in method_2_kwargs.items()])

    method_1_str = method_1 + '__' + '_'.join([f'{k}_{v}' for k, v in method_1_kwargs.items()])
    col_suffix = (method_1_str + '__' + method_2_str).strip('_')

    if isinstance(df_feature_stats, pd.Series):
        df_feature_stats = df_feature_stats.to_frame()
    else:
        df_feature_stats = df_feature_stats.pipe(add_col_suffix, '__' + col_suffix)

    if len(col_names) > 0:
        assert len(col_names)==len(df_feature_stats.columns)
        df_feature_stats.columns = col_names

    return df_feature_stats

def create_combined_feature_stats(
    df_features: pd.DataFrame,
    feature_stat_params: list
):
    df = pd.concat([
        create_feature_stats(df_features, **feature_stat_param)
        for feature_stat_param
        in feature_stat_params
    ], axis=1)

    return df

def create_demand_stat_features(df_features: pd.DataFrame):
    feature_stat_params = [
        {
            'cols': ['value'],
            'method_1': 'ewm',
            'method_2': 'std',
            'method_1_kwargs': {'alpha': 0.9},
            'method_2_kwargs': {}
        },
        {
            'cols': ['value'],
            'method_1': 'ewm',
            'method_2': 'mean',
            'method_1_kwargs': {'alpha': 0.9},
            'method_2_kwargs': {}
        },
        {
            'cols': ['value'],
            'method_1': 'ewm',
            'method_2': 'mean',
            'method_1_kwargs': {'alpha': 0.01},
            'method_2_kwargs': {}
        },
        {
            'cols': ['value'],
            'method_1': 'rolling',
            'method_2': 'max',
            'method_1_kwargs': {'window': 12},
            'method_2_kwargs': {}
        },
        {
            'cols': ['value'],
            'method_1': 'rolling',
            'method_2': 'min',
            'method_1_kwargs': {'window': 24},
            'method_2_kwargs': {}
        }
    ]

    df_combined_feature_stats = create_combined_feature_stats(df_features, feature_stat_params)

    return df_combined_feature_stats

# Cell
def create_solar_features(
    df_features: pd.DataFrame,
    sites: list=['staplegrove'],
    grid_points: type(None)=None,
):
    grid_points_original = copy(grid_points)
    feature_stats_dfs = []

    for site in sites:
        if grid_points_original is None:
            grid_points = get_grid_points(df_features, site)

        feature_stat_params_1 = [
            {
                'cols': [f'solar_irradiance_{site}_{grid_point}' for grid_point in grid_points],
                'method_1': 'mean',
                'method_2': None,
                'method_1_kwargs': {'axis': 1},
                'method_2_kwargs': {},
                'col_names': [f'solar_irradiance_{site}_mean']
            },
            {
                'cols': [f'solar_irradiance_{site}_{grid_point}' for grid_point in grid_points],
                'method_1': 'max',
                'method_2': None,
                'method_1_kwargs': {'axis': 1},
                'method_2_kwargs': {},
                'col_names': [f'solar_irradiance_{site}_max']
            },
            {
                'cols': [f'solar_irradiance_{site}_{grid_point}' for grid_point in grid_points],
                'method_1': 'min',
                'method_2': None,
                'method_1_kwargs': {'axis': 1},
                'method_2_kwargs': {},
                'col_names': [f'solar_irradiance_{site}_min']
            },
        ]

        feature_stat_params_2 = [
            {
                'cols': [f'solar_irradiance_{site}_max', f'solar_irradiance_{site}_min', f'solar_irradiance_{site}_mean'],
                'method_1': 'diff',
                'method_2': None,
                'method_1_kwargs': {},
                'method_2_kwargs': {}
            },
            {
                'cols': [f'solar_irradiance_{site}_max', f'solar_irradiance_{site}_min', f'solar_irradiance_{site}_mean'],
                'method_1': 'ewm',
                'method_2': 'mean',
                'method_1_kwargs': {'alpha': 0.9},
                'method_2_kwargs': {}
            }
        ]


        df_combined_site_feature_stats_1 = create_combined_feature_stats(df_features, feature_stat_params_1)
        df_combined_site_feature_stats_1[f'solar_irradiance_{site}_range'] = df_combined_site_feature_stats_1[f'solar_irradiance_{site}_max'] - df_combined_site_feature_stats_1[f'solar_irradiance_{site}_min']
        df_combined_site_feature_stats_2 = create_combined_feature_stats(df_combined_site_feature_stats_1, feature_stat_params_2)

        feature_stats_dfs += [pd.concat([df_combined_site_feature_stats_1, df_combined_site_feature_stats_2], axis=1)]

    df_combined_feature_stats = pd.concat(feature_stats_dfs, axis=1)

    return df_combined_feature_stats

# Cell
def create_prev_month_stats_df(df_features: pd.DataFrame, df_target: pd.DataFrame):
    s_avg_to_max = df_target['value_max'] - df_features['value']
    s_avg_to_min = df_target['value_min'] - df_features['value']

    df_prev_month_stats = pd.DataFrame({
        'prev_month_max_avg': s_avg_to_max.resample('MS').mean().shift().reindex(s_avg_to_max.index).ffill().dropna(),
        'prev_month_max_max': s_avg_to_max.resample('MS').max().shift().reindex(s_avg_to_max.index).ffill().dropna(),
        'prev_month_min_avg': s_avg_to_min.resample('MS').mean().shift().reindex(s_avg_to_min.index).ffill().dropna(),
        'prev_month_min_min': s_avg_to_min.resample('MS').min().shift().reindex(s_avg_to_min.index).ffill().dropna()
    })

    return df_prev_month_stats

# Cell
def create_lagged_df(
    df_features: pd.DataFrame,
    feature_lags: dict={'value': [1]}
):
    lagged_feature_dfs = []

    for feature, lags in feature_lags.items():
        lagged_feature_dfs += [pd.DataFrame({
            f'{feature}_lag_{lag}': df_features[feature].shift(lag)
            for lag
            in lags
        })]

    df_lagged_features = pd.concat(lagged_feature_dfs, axis=1)

    return df_lagged_features

# Cell
def creat_demand_ts_pcs(
    df_features: pd.DataFrame,
    n_features: int=7*48
):
    df_trajectory_mat = df_features['value'].to_frame()

    for lag in range(1, n_features+1):
        df_trajectory_mat['value-'+str(lag)] = df_trajectory_mat['value'].shift(lag)

    df_trajectory_mat = df_trajectory_mat.dropna()

    pca = PCA(n_components = 20)
    pca.fit(df_trajectory_mat)

    PCs = pca.fit_transform(df_trajectory_mat)
    df_PCs = pd.DataFrame(data=PCs, columns = ['demand_pc'+str(i+1) for i in range(pca.n_components)], index=df_trajectory_mat.index)

    return df_PCs

# Cell
def create_rate_of_change_features(
    df_features: pd.DataFrame,
    features: dict={
        'value': 3
    }
):
    df_roc = pd.DataFrame(index=df_features.index)

    for feature, order in features.items():
        for derivative  in range(order):
            derivative  += 1

            if derivative == 1:
                df_roc[f'{feature}_diff_{derivative}'] = df_features[feature].diff()
            else:
                df_roc[f'{feature}_diff_{derivative}'] = df_roc[f'{feature}_diff_{derivative-1}'].diff()

    return df_roc

# Cell
def clean_and_normalise_data(
    df_features: pd.DataFrame,
    df_target: pd.DataFrame,
    x_mean: np.ndarray,
    x_std: np.ndarray,
    y_mean: np.ndarray,
    y_std: np.ndarray,
    x_dtype: str='float32',
    y_dtype: str='float32',
):
    df_features = np.asanyarray(df_features).astype(x_dtype)
    df_target = np.asanyarray(df_target).astype(y_dtype)

    df_features_cleaned = (df_features - x_mean)/x_std
    df_target_cleaned = (df_target - y_mean)/y_std

    return df_features_cleaned, df_target_cleaned

def process_features(
    df_features: pd.DataFrame,
    cols_subset = ['value', 'temperature_staplegrove_1', 'solar_irradiance_staplegrove_1', 'windspeed_north_staplegrove_1',
                   'windspeed_east_staplegrove_1', 'pressure_staplegrove_1', 'spec_humidity_staplegrove_1', 'hour', 'doy',
                   'weekend', 'direction_staplegrove_1', 'speed_staplegrove_1', 'hcdh_staplegrove_1'],
):
    if cols_subset is None:
        return df_features

    df_features_processed = df_features.copy()

    common_cols_subset = df_features_processed.columns.intersection(pd.Index(cols_subset))
    missing_cols = sorted(list(set(cols_subset) - set(common_cols_subset)))
    assert len(missing_cols)==0, f'The following columns are missing: {", ".join(missing_cols)}'

    df_features_processed = df_features_processed[cols_subset]

    return df_features_processed

def create_additional_features(
    df_features: pd.DataFrame,
    df_target: pd.DataFrame=None,
    features: list=['temporal', 'dir_speed', 'hcdh', 'prev_month_stats', 'lagged', 'solar', 'demand', 'ts_pcs', 'roc'],
    sites: list=['staplegrove'],
    grid_points: type(None)=[1],
    feature_lags: dict={
        'value': [1, 2, 3, 4, 5, 6, 48, 96, 336],
        'solar_irradiance_staplegrove_1': [1, 2],
        'temperature_staplegrove_1': [1, 2],
    },
    roc_features: dict={
        'value': 3
    },
    x_mean: np.ndarray=None,
    x_std: np.ndarray=None,
    y_mean: np.ndarray=None,
    y_std: np.ndarray=None,
    x_dtype: str='float32',
    y_dtype: str='float32',
    cols_subset: list=None,
    dropna: bool=True
):
    if 'solar' in features:
        df_solar = create_solar_features(df_features, sites=sites, grid_points=grid_points)
        df_features = df_features.merge(df_solar, left_index=True, right_index=True)

    if 'demand' in features:
        df_features = df_features.merge(create_demand_stat_features(df_features), left_index=True, right_index=True)

    if 'temporal' in features:
        df_features = df_features.merge(create_temporal_features(df_features), left_index=True, right_index=True)

    if 'dir_speed' in features:
        df_dir_speed = iterate_feature_gen_over_site_gridpoints(df_features, create_dir_speed_features, sites, grid_points)
        df_features = df_features.merge(df_dir_speed, left_index=True, right_index=True)

    if 'hcdh' in features:
        df_hcdh = iterate_feature_gen_over_site_gridpoints(df_features, create_hcdh_features, sites, grid_points)
        df_features = df_features.merge(df_hcdh, left_index=True, right_index=True)

    if 'ts_pcs' in features:
        df_features = df_features.merge(creat_demand_ts_pcs(df_features), left_index=True, right_index=True)

    if 'prev_month_stats' in features:
        assert df_target is not None
        df_features = df_features.merge(create_prev_month_stats_df(df_features, df_target), left_index=True, right_index=True)

    if 'lagged' in features:
        df_features = df_features.merge(create_lagged_df(df_features, feature_lags), left_index=True, right_index=True)

    if 'roc' in features:
        df_features = df_features.merge(create_rate_of_change_features(df_features, roc_features), left_index=True, right_index=True)

    if dropna == True:
        df_features = df_features.dropna()

    if x_mean is None:
        x_mean = np.mean(df_features, axis=0)
    if x_std is None:
        x_std = np.std(df_features, axis=0)

    if df_target is not None:
        if y_mean is None:
            if isinstance(df_target, pd.Series):
                y_mean = df_target.mean()
            else:
                y_mean = np.mean(df_target, axis=0)
        if y_std is None:
            if isinstance(df_target, pd.Series):
                y_mean = df_target.std()
            else:
                y_mean = np.std(df_target, axis=0)

    # df_features = clean_and_normalise_data(df_features, df_target, x_mean, x_std, y_mean, y_std, x_dtype, y_dtype)
    df_features = process_features(df_features, cols_subset=cols_subset)

    return df_features, df_target